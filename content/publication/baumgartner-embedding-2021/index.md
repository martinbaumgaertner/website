---
title: "Whatever it takes to understand a central banker — Embedding their words using neural networks"
authors: ["Martin Baumgärtner", "Johannes Zahner"]
date: 2025-09-01
doi: "10.1016/j.jinteco.2025.104101"
tags:
  [
    "Word Embedding",
    "Neural Network",
    "Central Bank Communication",
    "Natural Language Processing",
    "Transfer Learning",
  ]
draft: false
image: "featured.png"

abstract: "Dictionary-based methods represent the most commonly used approach for quantifying the qualitative information from (central bank) communication. In this paper, we propose machine learning models that generate embeddings from words and documents. Embeddings are multidimensional numerical text representations that capture the underlying semantic relationships within text. Using a novel corpus of 22,000 documents from 128 central banks, we generate the first domain-specific embeddings for central bank communication that outperform dictionaries and existing embeddings on tasks such as predicting monetary policy shocks. We further demonstrate the efficacy of our embeddings by constructing an index that tracks the extent to which Federal Reserve communications align with an inflation-targeting stance. Our empirical results indicate that deviations from inflation-targeting language substantially affect market-based expectations and influence monetary policy decisions, significantly reducing the inflation response parameter in an estimated Taylor rule."

publication: "*Journal of International Economics*"
url_pdf: "https://doi.org/10.1016/j.jinteco.2025.104101"
---

## Authors

Martin Baumgärtner, Johannes Zahner

## Publication Details

**Journal:** Journal of International Economics
**Volume:** 157
**Date:** September 2025
**DOI:** [10.1016/j.jinteco.2025.104101](https://doi.org/10.1016/j.jinteco.2025.104101)

## Abstract

Dictionary-based methods represent the most commonly used approach for quantifying the qualitative information from (central bank) communication. In this paper, we propose machine learning models that generate embeddings from words and documents. Embeddings are multidimensional numerical text representations that capture the underlying semantic relationships within text. Using a novel corpus of 22,000 documents from 128 central banks, we generate the first domain-specific embeddings for central bank communication that outperform dictionaries and existing embeddings on tasks such as predicting monetary policy shocks. We further demonstrate the efficacy of our embeddings by constructing an index that tracks the extent to which Federal Reserve communications align with an inflation-targeting stance. Our empirical results indicate that deviations from inflation-targeting language substantially affect market-based expectations and influence monetary policy decisions, significantly reducing the inflation response parameter in an estimated Taylor rule.

## Links

- [Read on ScienceDirect](https://www.sciencedirect.com/science/article/pii/S0022199625000571)
- [DOI](https://doi.org/10.1016/j.jinteco.2025.104101)
